=============**미완성**=============
======
Chapter 7. 앙상블 학습과 랜덤 포레스트
=======
임의로 수천명에게 복잡한 질문을 물어보았다고 하고, 이들이 답해준 결과를 종합해본다고 하자. 대부분의 경우에서, 우리는 전문가 한명에게 묻는 것보다 이렇게 종합한 답변이 더 좋다는 것을 알게될 것이다. 이를 대중의 지혜(*wisdom of the crowds*)라고 한다. 이와 유사하게, 분류모델이나 회귀모델 같은 예측변수들의 그룹에 대한 예측치를 종합해보면, 종종 최고의 단일 예측변수만 사용하는 것보다 더 좋은 예측결과를 얻게된다. 예측변수들의 그룹을 앙상블(*Ensemble*)이라고 하며, 그래서 이러한 기법을 앙상블 학습(Ensemple Learning)이라고 하고, 앙상블 학습 알고리즘을 앙상블 기법(Ensemble method)라고 한다.

예로들어, 각각의 의사결정트리 분류모델을 서로다른 학습데이터의 서브셋으로 나눈것들로 학습시킬 수 있다. 예측결과를 내기 위해서, 처음에 각각의 모델에서 개별적으로 예측치를 낸다음에 거기서 나오는 결과로 투표하는 방식을 통하여 가장 많이 득표한 수를 예측값으로 출력해준다.(Chapter6의 마지막 연습문제를 참고하자) 이러한 의사결정트리의 앙상블을 랜덤 포레스트(Random Forest)라고 하며, 이는 아주 간단함에도 불구하고 오늘날에도 아주 강력한 기꼐학습알고리즘들 중 하나이다.

Chapter2에서 다루었던 것처럼, 이미 몇가지 좋은 예측변수들을 만들어보았으므로 좀 더 좋은 예측변수들을 얻기위해서 이러한 앙상블 기법을 종종 사용할 것이다. 사실은 기계학습 경진대회에서 우승하는 솔루션을 보면 심심치않게 앙상블 기법이 사용된다.

이번 Chapter에선, bagging(배깅), Boosting, Stacking과 같은 여러가지 유명한 앙상블 기법들에 대해서 얘기해볼 것이고, 또한 랜덤포레스트도 다룰것이다.
# 분류모델 투표
각각 약 80%정도의 정확도를 가지고 있는 학습된 분류 모델 몇개를 가지고 있다해보자. 아마 로지스틱 회귀 분류모델, SVM 분류모델, 랜덤포레스트 분류모델, KNN(K-Nearest Neighbors)분류 모델, 그 외의 분류모델을 가지고있을 것이다.
###### 그림 7-1. 다양한 분류모델 학습시키기
![](https://github.com/Hahnnz/handson_ml-Kor/blob/master/Book_images/07/7-1.png)

더 나은 분류모델을 만드는 가장 쉬운 방법은 각각의 모델들에 대한 예측치들을 종합하여 가장 많은 득표를 한 클래스로 예측하는 것이다. 이런 다수결분류모델을 엄격투표(*hard voting*)분류모델이라고 한다.
###### 그림 7-2. 엄격투표분류모델 예측
![](https://github.com/Hahnnz/handson_ml-Kor/blob/master/Book_images/07/7-2.png)

어떻게 된 일인지 투표로하는 분류모델이 종종 앙상블내에서 최고성능의 분류모델보다 더 높은 정확도를 보인다. 각각의 분류 모델들이 *weak learner*(막 찍는 분류모델보다 아주 약간 성능이 더 좋은 모델)임에도 불구하더라도, 이러한 앙상블들은 충분한 수의 *weak learner*에 충분히 다양하다면 *Strong learner*(높은 정확도를 보이는 것)가 될 수 있다.

어떻게 이게 가능한 것일까? 앞면이 나올 확률이 51%이고, 뒷면이 나올 확률이 49%인 약간 편향적인 코인에 대해서 생각해보자. 만약 동전을 1000번 던진다면 보통 일반적으로 생각해보면 약 510번은 앞면, 490번은 뒷면이라고 나올 것이고 그러면 다수결로 앞면이 채택될 것이다. 수학을 한다면, 1000번을 던지면 대부분 앞면이 나올 확률은 75%에 가깝다는 것을 알게될 것이다. 동전을 더 많이 던질수록, 그 정확도는 올라간다.(1만번 던지면, 확률은 약 97%까지 증가한다) 이는 큰 수의 법칙(*The Law of Large Number*)때문인데, 동전을 계속 던질수록, 앞면이 나올 비율은 가까워지고, 앞면이 나올 확률인 51에 근접하게 된다. 아래의 그림은 편향적인 동전 1만법 던지기를 10회 정도 한 것이다. 던지는 횟수가 증가할수록 앞면비율이 51%에 가까워지는 것을 볼 수 있다. 결국 10회 모두 50% 이상을 유지하면서 51%에 매우 가까워지게 될 것이다.
###### 그림 7-3. 큰 수의 법칙
![](https://github.com/Hahnnz/handson_ml-Kor/blob/master/Book_images/07/7-3.png)

이와 유사하게, (무작위 분류모다 조금 좋은) 개별적으로 51%정도만 맞는 1000개의 분류 모델을 가지고 있는 앙상블을 만들었다고 하자. 만약 다수결로 뽑힌 클래스로 예측을 한다면, 75%정도의 정확도로 높이고싶을 것이다. 하지만 모든 분류모델들이 서로 독립적이고 연관이없는 에러치를 가지는 경우에만 해당이 된다. 모두 같은 데이터 세트로 학습시키는 경우 같은 종류의 에러를 만들어내서 앙상블 정확도는 줄어 다수결 투표는 잘못된 클래스에 투표할 것이다.
```
앙상블 기법은 가능한 각각의 예측변수들이 서로 독립적일때 아주 잘 작동한다. 다양한 분류모델을 
얻는 방법은 여러가지 알고리즘들로 학습하는 것이다. 이는 앙상블의 정확도는 상승하지만 매우
다양한 형태의 에러치를 얻을 기회도 증가한다. 
```
아래의 코드는 Scikit-Learn에서 투표 분류모델을 만들어 학습시키는 코드로, 세개의 다양한 분류모델로 구성되었다.(학습 데이터 세트는 chapter5에서 소개가 되었던 moons 데이터세트를 사용하였다)
```
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

log_clf = LogisticRegression(random_state=42)
rnd_clf = RandomForestClassifier(random_state=42)
svm_clf = SVC(random_state=42)

voting_clf = VotingClassifier(
    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],
    voting='hard')
voting_clf.fit(X_train, y_train)
```
테스트 데이터 세트로 각각의 분류모델의 정확도를 보자
```
>>> from sklearn.metrics import accuracy_score
>>> for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
...     clf.fit(X_train, y_train)
...     y_pred = clf.predict(X_test)
...     print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
... 
LogisticRegression 0.864
RandomForestClassifier 0.872
SVC 0.888
VotingClassifier 0.896
```
투표 분류 모델이 모든 개별적 분류 모델보다는 조금더 성능이 향상되었다. 
만약 모든 분류모델이 클래스에 대한 확률치 평가가 가능하다면(`predict_proba()`기법을 가지고 있다), Scikit-Learn을 사용해서, 가장 높은 확률치와, 모든 분류 모델에 대한 평균치로 클래스를 예측할 수 있다. 이를 유연한 투표(*soft voting*)이라고 한다. 종종 엄격한 투표보다 더 좋은 수행능력을 보여주는데, 이는 좀 더 신뢰되는 표에 가중치를 줄 수 있기 때문이다. 우리가 해야할 것은 `voting="hard"`에서 `voting="soft"`로 바꾸어주고 모든 분류모델들이 클래스에 대한 확률치로 평가되기만 하면 된다. SVC 클래스의 경우에는 기본값으로 설정된 것이 아니므로 `probability` 하이퍼 파라미터를 `True`로 설정해주면 된다. (이는 SVC 클래스가 클래스에 대한 확률치로 평가하기 위해서 Cross-validation을 사용하게하고, 학습은 느려지겠지만 `predict_proba()`기법을 사용할 수 있게될 것이다) 만약 유연한 투표로 실행코드를 바꾼다면 투표 분류모델의 정확도가 91%까지 증가하는 것을 볼 수 있을 것이다.  
# Bagging and Pasting
분류모델의 다양한 셋을 얻는 방법은 앞에서 언급했다시피 다양한 학습 알고리즘을 사용하는 것이다. 또다른 접근법은 모든 예측변수들에게 같은 학습 알고리즘을 사용하게하고 학습 데이터 세트의 서로다른 서브셋을 각각 학습시키는 것이다. replacement과정을 포함해서 샘플링한다면 이를 [배깅(Bagging)](http://goo.gl/o42tml)이라고 하며, 반대로 replacement 과정 없이 샘플링한다면 이를 [패스팅(Pasting)](http://goo.gl/BXm0pm)이라고 한다.

다른말로 배깅과 패스팅 모두 학습 인스턴스들이 다중 예측변수들에 대해서 여러번 샘플링 되도록 해주지만, 배깅만 학습 인스턴스가 같은 예측변수에 대해서 몇번이고 샘플링 될 수 있도록 한다. 이러한 샘플링과 학습 프로세스는 아래의 그림에 아주 잘 나타나있다.
###### 그림 7-4. Pasting/bagging 학습 데이터세트 샘플링 및 학습
![](https://github.com/Hahnnz/handson_ml-Kor/blob/master/Book_images/07/7-4.png)

모든 예측변수들이 학습되면, 앙상블은 모든 예측변수들에 대해서 예측값을 종합하여 새로운 인스턴스에 대해서 예측을 내린다. 이를 종합하는 함수는 전형적으로 분류 혹은 회귀에 대한 평균치에 대해서 *statistical*(가장 자주나온 예측값, 마치 엄격투표분류모델 처럼)모드이다. 일반적으로, 이런 망의 결과치는 앙상블은 동일한 편향치를 가지고 있지만 오리지널 데이터 세트로 학습된 단일 예측변수보다 변화량이 더 작다. 그림 7-4에서 본 것처럼, 예측변수는 서로다른 CPU코어를 사용하거나 각각 다른 서버를 사용해서 모두 병렬로 학습을 할 수 있다. 이와 유사하게 예측도 병렬로 수행되어 만들어진다. 배깅과 패스팅이 이렇게나 인기있는 이유는 스케일링을 아주 잘하기 때문이다.  
## Scikit-Learn에서의 Bagging and Pasting
Scikit-Learn은 `BaggingClassifier`라는 클래스로 배깅과 패스팅 모두를 지원하는 API를 제공한다. 다음의 코드는 replacement를 사용하여 학습 데이터 세트를 임의로 각각 100개씩의 인스턴스로 나누어 각각 500개의 의사결정트리의 앙상블로 학습을 시키는 코드이다.(이것이 배깅의 예제인데, 만약 패스팅을 대신 사용하고자 한다면, `booststrap=False`라고 설정을 해주면 된다)
## Out-of-bag 평가법
# 랜덤 패치 및 랜덤 부분공강
# 랜덤 포레스트
## 추가 트리
## 특징 중요성
# 부스트 사용하기(Boosting)
## 에이다부스트(AdaBoost)
###### Equation 7-1. j번째 예측변수에 대한 가중치 에러율
![]()
###### Equation 7-2. 예측변수 가중치
![]()
###### Equation 7-3. 가중치 업데이트 규칙
![]()
###### Equation 7-4. AdaBoost 예측변수
![]()
## 가중치 부스트(Gradient Boosting)
# Stacking

**[뒤로 돌아가기](https://github.com/Hahnnz/handson_ml-Kor/)**
