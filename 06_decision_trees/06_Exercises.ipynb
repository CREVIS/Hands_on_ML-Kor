{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백만개의 인스턴스를 가지고 있는 학습 데이터에 대해서 학습한 의사결정트리(제한사항 없이)의 근사 높이는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 노드가 일반적으로 gini 불순도 측정치가 자신의 부모 노드보다 더 높은가 아니면 낮은가? 일반적으로 그런 것인가 아니면 항상 그러는 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 의사결정나무가 학습 데이터 세트에 대하여 과잉학습(Overfitting)을 하였다면, `max_depth`를 줄이는 것이 좋은 아이디어인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 의사결정나무가 학습 데이터 세트에 대하여 저학습(underfitting)을 하였다면, 입력 특징 값을 스케일링하는 것이 좋은 아이디어인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백만개의 인스턴스를 가지고 있는 학습 데이터 셋에 대해서 의사결정나무를 학습시키는데 1시간정도 걸렸다면, 천만개의 인스턴스를 가지고 있는 학습 데이터세트에 대해서 또다른 의사결정함수를 학습시키는데 대략 얼마나 시간이 걸릴 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 학습 데이터 세트가 10만개의 인스턴스를 가지고 있는데 `presort=True`라고 설정하면 학습 속도가 증가할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "답답\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moons 데이터세트에 대해서 의사결정함수를 학습시켜보고 조율해보자.\n",
    "  * a. `make_moons(n_samples=10000, noise=0.4)`를 사용해서 moons 데이터 세트를 생성해보자.\n",
    "  * b. `train_test_split()`함수를 사용하여 학습 데이터와 테스트 데이터를 나누자.\n",
    "  * c. `DecisionTreeClassifier`에 좋은 하이퍼파라미터 값을 찾기 위해 cross-validation으로 grid search를 해보자. (`GridSearchCV`클래스가 도움이 될 것이다)\n",
    "    * **Hint** : `max_leaf_nodes`에 대해서 여러가지 값들을 시도해보자\n",
    "  * d. 여기서 찾은 하이퍼 파라미터들로 전체 학습 데이터 세트를 학습시켜보고, 테스트 데이터 세트로 여러분들의 모델 수행능력을 측정해보자. 85~87%의 정확도가 나와야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. `make_moons(n_samples=10000, noise=0.4)`를 사용해서 moons 데이터 세트를 생성해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 Notebook의 결과를 변함 없게 하기위해 랜덤 시드값를 설정하자.:`random_state=42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. `train_test_split()`함수를 사용하여 학습 데이터와 테스트 데이터를 나누자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. `DecisionTreeClassifier`에 좋은 하이퍼파라미터 값을 찾기 위해 cross-validation으로 grid search를 해보자. (`GridSearchCV`클래스가 도움이 될 것이다)\n",
    "\n",
    "*Hint*:`max_leaf_nodes`에 대해서 여러가지 값들을 시도해보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': [2, 3, 4], 'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # GridSearchCV 클래스 호출\n",
    "from sklearn.tree import DecisionTreeClassifier # Scikit-Learn의 의사결정분류모델 호출\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=17,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 여기서 찾은 하이퍼 파라미터들로 전체 학습 데이터 세트를 학습시켜보고, 테스트 데이터 세트로 여러분들의 모델 수행능력을 측정해보자. 85~87%의 정확도가 나와야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본값으로, `GridSearchCV`는 전체 학습 데이터 세틑에 대하여 최고의 모델를 찾도록 학습을 진행한다. (`refit=False`로 설정하여 이를 변경해줄 수도 있다.) 그래서 우리는 이를 다시 할 필요가 없다. 우리는 그냥 모델의 정확도만 평가하면된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86950000000000005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숲을 키워보자.\n",
    "  * a. 이전 연습 문제에 이어서, 각각 랜덤적으로 선택된 100개의 인스턴스를 가지도록 학습 데이터 세트에서 1000개의 서브셋를 생성해보자. \n",
    "    * **Hint** : Scikit-Learn의 `ShuffleSplit`클래스를 사용해보자.\n",
    "  * b. 위에서 찾은 최고의 하이퍼 파라미터 값들로 각각의 서브셋에 대해서 의사결정트리를 학습시키자. 더 작아진 서브셋으로 학습을 하고 있기때문에, 이 의사결정트리는 정확도 80%정도를 웃돌면서, 첫번째 의사결정트리보다는 성능이 안좋을것이다. \n",
    "  * c. 마법을 부릴 시간이다. 각각의 테스트 셋의 인스턴스에 대해서 1000개의 의사결정함수에 대한 예측값을 내고, 가장 자주 나오는 예측치를 저장해보자.(SciPy의 `mode()`라는 함수를 사용하여 진행하는 것을 추천한다) 이는 전체 학습 데이터 세트에 대해서 가장 높은 예측치를 투표할 것이다.\n",
    "  * d. 테스트 데이터로 나온 예측치를 평가해보자. 첫번째 모델의 평가치보다 약 0.5~1.5정도 더 높은 정확도를 얻을 것이다. 이것이 바로 랜덤포레스트라는 것이다. 축하한다. 랜덤포레스트를 방금 막 만들어 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. 이전 연습 문제에 이어서, 각각 랜덤적으로 선택된 100개의 인스턴스를 가지도록 학습 데이터 세트에서 1000개의 서브셋를 생성해보자.\n",
    "\n",
    "*Hint* : Scikit-Learn의 `ShuffleSplit`클래스를 사용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)\n",
    "for mini_train_index, mini_test_index in rs.split(X_train):\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    mini_sets.append((X_mini_train, y_mini_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. 위에서 찾은 최고의 하이퍼 파라미터 값들로 각각의 서브셋에 대해서 의사결정트리를 학습시키자. 더 작아진 서브셋으로 학습을 하고 있기때문에, 이 의사결정트리는 정확도 80%정도를 웃돌면서, 첫번째 의사결정트리보다는 성능이 안좋을것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80544949999999993"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 마법을 부릴 시간이다. 각각의 테스트 셋의 인스턴스에 대해서 1000개의 의사결정함수에 대한 예측값을 내고, 가장 자주 나오는 예측치를 저장해보자.(SciPy의 `mode()`라는 함수를 사용하여 진행하는 것을 추천한다) 이는 전체 학습 데이터 세트에 대해서 가장 높은 예측치를 투표할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 테스트 데이터로 나온 예측치를 평가해보자. 첫번째 모델의 평가치보다 약 0.5~1.5정도 더 높은 정확도를 얻을 것이다. 이것이 바로 랜덤포레스트라는 것이다. 축하한다. 랜덤포레스트를 방금 막 만들어 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
