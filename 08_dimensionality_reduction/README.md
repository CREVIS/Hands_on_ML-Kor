Chapter 8. 차원감소법
==============
기계학습 문제에서 각각의 학습 인스턴스에 수천개 혹은 심지어 수천만개의 특징값이 연관지어져있다. 이는 학습 속도를 극심하게 느리게할 뿐만 아니라, 앞으로 볼 것이지만 좋은 솔루션을 찾아가는데 더 어려워진다. 이러한 문제를 종종 *차원수의 저주(Curse of Dimensionality)* 라고 한다.

그래도 실제 세계의 문제에선 아주 다루기 힘든 문제를 다루기 쉬운 것으로 바꾸어서 특징값의 수를 상당히 줄이는 것이 가능하다. MNIST 이미지에 대해서 생각해보자. 이미지 경계선에 있는 픽셀들은 대부분이 하얀색이다. 그래서 정보손실을 많이 발생시키지 않으면서 학습 데이터 세트에서 이러한 픽셀들을 버릴 수 있다. 그림 7-6을 보면 분류에 있어 이러한 픽셀들은 아주 불필요한 것임을 보여주고 있다. 좀 더 나아가서 서로 근접해있는 두개의 픽셀은 종종 높게 연관지어진다. 만약 이 두개의 픽셀을 하나의 픽셀로 합친다면,(두 픽셀의 진함의 정도를 평균 내어) 정보손실을 줄일 수 있을 것이다.
```
차원수를 줄인다는 것은 어느정도의 정보손실이 발생한다. (마치 이미지를 JPEG로 압축하면 이미지의
퀄리티가 감소하는 것같은 것이다) 그래서 학습 속도를 올릴 수 있겠지만, 우리가 구현하는 분석 시스템의
수행능력을 더 나쁘게 만들 수 도 있다. 또한 파이프라인을 좀 더 복잡하게 만들어야해서 유지보수에 조금
더 어려움이 있다. 그러므로 학습속도가 너무 느려서 차원감소법을 사용하기 전에 먼저 원본 데이터 세트로
학습을 시켜볼 필요가 있다. 일부의 경우에서는 학습데이터의 차원의 수를 줄이는 것이 노이즈와 불필요한
사항들을 걸러 내주어 좀 더 좋은 퍼포먼스를 보여주기도 한다. (하지만 일반적으로는 그렇지 않으며 그냥
학습 속도가 증가하는 것이다)
``` 
학습 속도를 증가시키는 것을 떠나서, 차원감소법은 데이터 시각화에 아주 유용하며, 차원의 수를 2~3차원으로 감소시키는 것은 고차원 학습 데이터 세트를 그래프로 그릴 수 있게 해주며 종종 클러스터를 만드는 알고리즘에서 시각적으로 패턴을 발견해서 중요한 통찰을 얻을 수 있게 해준다.

이번 Chapter에서는 차원수의 저주에 대해서 다루어 볼 것이며, 고차원 공간에 대한 공부를 해볼 것이다. 그리고나서 차원감소법에 대한 두가지 주된 접근법인 투영법(Projection)과 매니폴드 학습(Manifold Learning)에 대해서 볼 것이다. 그리고 세가지의 가장 인기있는 차원감소법 기술인 PCA, Kernel PCA ,LLE에 대해서도 이야기해볼 것이다.

# 차원수의 저주
우리가 사는 세계가 3차원이라 이에 너무 익숙해져있어서 고차원 공간에 대해서 상상해보기가 너무 어렵다. 심지어 200차원의 타원체를 1000차원으로 욱여넣는것은 고사하고 기본적인 4차원 하이퍼큐브(아래의 그림 참고)도 우리의 마음속으로 그려보기가 어렵다. 
###### 그림 8-1. 점, 선, 정사각형, 정사면체, 초입방체 (0차원부터 4차원까지)
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-1.png)

고차원 공간에서 많은 것들이 서로 매우 다르게 움직이는 것을 보여주고 있다. 예를들어 단위사각형 1x1에 랜덤으로 점을 찍어본다면, 경계선으로부터 0.001이하로 배치될 확률이 약 0.4%정도밖에 되지않는다. (다른말로 임의의 점이 어떤 차원 사이에서 (경계값에 가깝게)가장 멀리 배치되지 않는다는 것을 말한다) 하지만 10000차원의 단위하이퍼큐브(1x1x1x...x1), 1만개의 1로 이루어진 큐브에서는 이 확률이 99.999999%보다 더 높다. 고차원의 하이퍼큐브에서 대부분의 점들은 경계선과 아주 가깝다.

여기 좀 더 고질적인 차이점이 있다. 단위 사각형에서 두개의 지점을 임의로 뽑는다면, 평균적으로 두 점 사이의 거리는 거의 0.52이다. 만약 단위 3차원 큐브에서 두개의 임의의 점을 뽑는다면, 평균 거리가 약 0.66이다. 그렇다면 만약 백만차원의 하이퍼큐브에서 두개의 지점을 임의로 두 점을 고른다면 어떨까? 믿거나 말거나 평균 거리는 (거의 √(1,000,000)/6 의 수치와 비슷한) 약 408.25이다. 이는 아까 나온 결과랑 비교해보면 전혀 기대치 못한 수치이다. 어떻게 두 점이 같은 단위 하이퍼 큐브 내에 있음에도 불구하고 저렇게나 멀리 떨어져 있다고 나오는 것일까? 이러한 사실은 고차원의 데이터 세트가 분포가 매우 희박하게 되어있는 것에 대한 위험성이 있음을 암시해준다. 즉 학습의 인스턴스가 많을수록, 서로 멀어지는 경향이 있다는 것이다. 당연히, 이는 새로운 인스턴스에 대해서 어느 학습 인스턴스와고도 멀리 떨어지게 되며, 또한 좀 더 큰 외삽법(extrapolations)에 기반을 하고 있기 때문에, 예측을 할 때 낮은레벨의 차원의 것보다 믿음직스럽지 못하게 된다. 짧게 말해서, 학습 데이터 세트가 차원수를 더 많이 가질수록, 오버피팅의 위험이 더 증가한다는 것이다.

이론적으로, 차원수의 저주에서 벗어나는 솔루션으로는 학습 인스턴스가 충분한 밀도를 가질때까지 학습 데이터 세트의 크기를 늘리는 것이다. 불행하게도, 실세계에서는 주어진 밀도를 만족하는 학습 인스턴스의 수는 차원의 수를 기하급수적으로 키운다. 특징수 100개로도 우리는 관측가능한 우주에 있는 모든 원자수들 보다 더 많은 학습 데이터 수를 채워야만 한다. 

# 차원 감소법의 주된 접근법
특정 차원 감소법 알고리즘에 뛰어들기전에, 두 가지의 차원수를 줄이는 주된 접근법에 대해서 살펴보자. 

## 투영법(Projection)
실제 세계의 대부분의 문제에서, 학습 인스턴스는 모든 차원에 대해서 골고루 퍼져있지않다. 많은 특징값들은 거의 변함이 없는 값들이지만 서로 높게 관련되어있다. 결국에는, 모든 학습 인스턴스들은 실제로 고차원의 공간에 대한 하위 차원의 부분공간(subspace)에 놓여있거나 가까이 있다. 이는 매우 추상적인 소리이므로 한번 예시를 보자. 아래의 그림은 동그라미로 표현된 3차원 데이터 세트를 보여준다.
###### 그림 8-2. 2차원 부분공간에 가깝게 놓여있는 3차원 데이터세트
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-2.png)

모든 학습 인스턴스가 평면에 가깝게 놓여있다. 이 평면은 3차원이라는 고차원 공간에 대한 2차원 하위 차원공간이다. 이제 만약 우리가 이 평면을 수직으로모든 학습 인스턴스들(인스턴스와 평면이 선으로 짧게 연결이 되어있는 것도 포함)을 투영시키면 우리는 이제 아래의 그림처럼 보여지는 새로운 2차원 데이터 세트를 얻게된다.
###### 그림 8-3. 투영을 하여 얻은 새로운 2차원 데이터 세트
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-3.png)

하지만 투영법이 차원 감소법에 대해서 항상 최고의 접근법이 되지는 못한다. 실제로 많은 경우에서, 부분 공간은 꼬여있거나 구부러져있는 형태를 띤다. 예로, *Swiss roll toy* 데이터 세트가 아래의 그림에 나와있다.
###### 그림 8-4. *Swiss roll toy* 데이터 세트
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-4.png)

한 평면을 투영하면 아래의 왼쪽 그림에 나와있는 것처럼, 일부 계층을 덮어내면서 출력을 하기도 한다. 하지만 실제로 우리가 원하는 것은 아래 오른쪽 그림에 나와있는 것같이 Swiss roll을 풀어주는 2차원 데이터 세트를 얻는 것이다.
###### 그림 8-5. (왼쪽) 평면 투영으로 눌러내기 / (오른쪽) Swiss roll 롤 풀기
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-5.png)
## 매니폴드 학습법(Manifold Learning)
Swiss roll은 2차원 매니폴드의 좋은 예이다. 간단히 말해서 2차원 매니폴드라는 것은 더 높은 차원공간에서 욱여져있고 구부러져 있는 2차원 형태를 말한다. 더 일반적으로, d-차원의 매니폴드는 d-차원의 하이퍼플레인이 가까이 모여있는 (d < n)n차원의 일부를 일컫는다. Swiss roll같은 경우에는, d=2, n=3이고, 2차원 평면이 서로 가까이 모여있는 형태이지만, 3차원공간에 말려있다.

많은 차원감소법 알고리즘들은 학습 인스턴스가 놓여있는 매니폴드를 모델링하는 것으로 움직이게 되는데 이를 매니폴드 학습법이라고 한다. 이는 매니폴드 가정에 의존하는 것이며, 이를 또한 매니폴드 가설(*Manifold hypothesis*)이라고 한다. 이는 대부분의 고차원 데이터 세트가 하위 차원 매니폴드에 가까이 놓여있다는 것을 말해준다. 이러한 가정은 매우 자주 경험적으로 관측된다.

다시 MNIST 데이터 세트에 대해서 생각을 해보자. 손으로 작성된 숫자 이미지들은 어느 정도의 유사성을 가지고 있다. 이들은 선으로 연결된 선으로 만들어져있으며, 경계선은 하얀색이고, 대부분이 어느정도 중앙에 배치가 되어있고, 등등.. 만약 임의으로 이미지를 생성했다면, 그들 중 터무니없이 아주 적은 일부만 손으로 작성한 숫자처럼 보일 것이다. 다른말로, 만약 숫자 이미지를 만들려서 시도한다면 우리에게 허락된 자유도는 우리가 원하는 어떠한 이미지들 생성하는 것이 가능하다면 가지는 자유도보다 더 낮다. 이러한 제한사항들은 데이터 세트를 하위 차원의 매니폴드에 꽉곽 눌러담게된다.

매니폴드 가정은 종종 또 다른 내포된 가정이 따라오는데, 하고자 하는 것(분류, 회귀)가 매니폴드의 하위 공간에서 표현되어질 수 있다면 더 간단해질 수 있다는 것이다. 예를 들어, 아래 그림의 맨 위쪽 그림들은 3차원 공간에서 2개의 클래스로 Swiss roll을 나눌 수 있으며(왼쪽 그림), 의사 결정선은 꽤 복잡해 질 것이다. 하지만 이를 2차원에 매니폴드 공간으로 풀어낸다면 (오른쪽 그림), 의사 결정선은 아주 간단하게 직선으로 그려질 수 있다.

하지만 이러한 가정이 항상 맞아 떨어진다는 보장이 없다. 예로들어 아래의 그림에서 아래의 있는 그림들에서, x1=5 지점에서 의사 결정선(수직 평면)이 원본 3차원 공간에서 아주 간단하게 보여지는데 이를 매니폴드 공간으로 풀어내게되면 더욱 복잡해지는 것을 알 수 있다.

짧게 말해서, 만약 모델을 학습시키기 전에 학습 데이터 세트의 차원을 줄이면, 분명히 속도가 증가할지라도, 이것이 항상 더 좋은 솔루션을 가져올 수 없다는 것을 알아야한다. 이는 모두 데이터세트에 달려있는 것이다.

다행스럽게도, 우리는 무엇이 차원수의 저주인지에 대한 이해와 특히 매니폴드 가정을 두고 어떻게 차원감소법 알고리즘이 이에 대해서 작동하는지에 대한 이해를 얻게 되었다. 이 Chapter의 나머지 부분들은 가장 인기가 있는 알고리즘들 중 몇가지를 다루어 볼 것이다. 
###### 그림 8-6. 의사결정선이 항상 하위 차원으로 풀어도 간단해지지 않을지도 모른다.
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-6.png)
# PCA
주성분 분석법(*Principal Component Analysis*)이라고 하는 PCA는 단연코 가장 인기가 있는 알고리즘이다. 먼저 이는 데이터가 가장 가까이 놓여있는 하이퍼플레인을 찾아내고 데이터에 이를 투영시켜낸다.
## 분산도 유지하기
하위 차원의 하이퍼 플레인에 학습 데이터 세트를 투영시키기 전에, 먼저 올바른 하이퍼플레인을 선택할 필요가 있다. 예를들어 2차원 데이터 세트는 3개의 축에 따라서 아래 왼쪽 그림(1차원 하이퍼플레인)으로 표현될 수 있다. 오른쪽에 있는 그림은 각각의 축들에 대해서 데이터 셋을 투영한 결과이다. 보다시피, 실선상으로 투영한 것은 최대 분산을 유지해주지만 점선상에 투영을 한 것은 분산도가 매우 작고 대쉬선상에 투영시킨 것 또한 분산도가 중간정도 수준이다. 
###### 그림 8-7. 투영을 시킬 부분 공간 선택
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-7.png)

분산도가 최대가 되도록 해주는 축을 선택하는 것이 가장 합당한데, 이는 다른 축에 투영시키는 것보다 가장 정보손실을 줄일 수 있기 때문이다. 이런 선택을 정당화할 수 있는 또다른 방법은 원본 데이터 세트와 이것이 투영된 축상 사이의 거리에 대한 MSE를 최소화해주는 축이라는 것이다. 
## 주성분(Principal Components)
PCA는 학습 데이터 세트에서 분산치가 가장 높게 차지하는 축을 찾아낸다. 위의 그림에서 이는 실선으로 표현된 것이다. 이는 또한 첫번째 축과 직교하는 두번째 축을 찾아내는데 이는 잔존 분산도가 최대가 되도록 해주는 축이다. 2차원에서는 선택 사항이 없으며 이 두번째 축은 점선으로 표시가 되어있다. 만약 더 높은 차원의 데이터 세트가 있다면, PCA는 또한 세번째 축도 만들 것이며, 이전의 두개의 축과 직교하게되어야하며, 4차원, 5차원도 이런식으로 증가하게 된다. 데이터셋의 차원수만큼 이 축의 수가 증가하게 된다.

i번째의 축을 정의하는 단위벡터를 i번째의 주성분,PC(*Principal Component*)라고 한다. 그림 8-7에서, 첫번째 PC는 c1이고, 두번째 PC는 c2이다. 그림 8-2에서는 평면상에서 직교로 화살표로 첫번째와 두번째 PC가 표현이 되어있다. 그리고 세번째 PC는 평면과 직교가 되는 것으로 위 아래를 표시해주는 화살표로 표시될 것이다. 
```
PC의 방향은 안정적이지 못하다. 만약 학습 데이터 세트를 조금 변형시키어서 PCA를 다시 돌려보면
기존 PC의 정반대 방향으로 가르키는 새로운 PC가 만들어질 수도 있다. 하지만 일반적으로 축 자체의
위치는 변하지 않는다. 일부 경우에서는 PC의 쌍이 돌려지거나 스와핑될 수 있지만, 정의한 평면은
똑같이 남아있을 것이다.
```
그래서 학습 데이터 세트에서 PC를 어떻게 찾을 수 있을까? 학습 데이터 세트 행렬 X를 우리가 찾고있는 모든 PC값을 포함하고 있는 **V**^T를 가진 세개 행렬의 내적 **U**⋅**∑**⋅**V**^T로 분해하는 단일값 분해법(*Singular Value Decomposition, SVD*)이라고 하는 표준 행렬 인수분해법이 있다. 공식 8-1로 보여진다.
###### Equation 8-1. 주성분 행렬 (Principal Component Matrix)
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/Eq8-1.png)

다음의 파이썬 코드는 학습 데이터 세트의 모든 PC값을 얻는 NumPy의 `svd()`함수를 사용하고나서 첫번째와 두번째 PC를 추출한 것이다.
```
X_centered = X - X.mean(axis=0)
U, s, Vt = np.linalg.svd(X_centered)
c1 = Vt.T[:, 0]
c2 = Vt.T[:, 1]
```
```
PCA는 데이터 세트가 Origin 중심 주위에 모여있다고 가정한다. 앞으로 볼 것이지만, Scikit-Learn의
PCA 클래스는 데이터를 중심으로 모아준다. 하지만 PCA를 직접 구현하거나 다른 라이브러리를 사용한다면, 
데이터를 중심으로 모으는 작업을 잊지말자.
```
## d-차원 투영하기
모든 PC를 확인하고나면, 첫번째 d 주성분으로 정의되는 하이퍼플레인 상에서 d-차원을 투영시킴으로써 데이터 세트의 차원을 줄일 수 있다. 하이퍼플레인을 선택하는 것은 가능한 제일 커다란 분산도를 가지도록 하는 투영 결과를 보장할 수 있어야 한다. 예를들어 그림 8-2에서 3차원 데이터세트는 데이터 세트의 분산도를 가장 높게 유지해주는 첫번째와 두번째 주성분 축으로 정의되는 2차원 평면에 투영시킨다. 결과적으로는, 2차원 투영법은 기존 3차원 데이터 세트와 꽤나 유사해보인다.

하이퍼플레인에 학습 데이터 세트를 투영시키기 위해서는, 행렬 **W**b로 학습 데이터 세트 행렬 **X**를 내적해서 구할 수 있으며, 첫번째 d-주성분을 포함하고 있는 행렬로 정의되어진다. 이는 아래의 식으로 표현되어 있다.
###### Equation 8-2. d-차원으로 학습 데이터 세트 투영시키기
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/Eq8-2.png)

아래의 파이썬 코드는 첫번째와 두번째 주성분들로 정의된 평면에 학습 데이터 세트를 투영시키는 코드이다.
```
W2 = Vt.T[:, :2]
X2D = X_centered.dot(W2)
```
이제 어떠한 데이터 세트를 어떠한 차원수로 차원수를 낮추면서도 가능한 분산도를 많이 유지하는 방법을 알게되었다!
### Scikit-Learn을 사용해서
Scikit-Learn의 `PCA`클래스는 우리가 전에 했던 것처럼 SVD 분해함수를 사용해서 PCA를 구현하였다. 다음의 코드는 2차원으로 데이터 세트의 차원수를 줄여주는 PCA를 적용한 것이다. (자동으로 데이터 세트를 중앙으로 모으는 작업을 해줌)
```
from sklearn.decomposition import PCA

pca = PCA(n_components = 2)
X2D = pca.fit_transform(X)
```
dataset로 `PCA`변환함수를 fitting을 시키고나면, `components_`변수를 사용해서 주성분에 접근할 수 있다. (수평벡터써 PC를 포함하고 있다는 것을 알 필요가 있다.예로, 첫번째 주 성분은`pca.components_.T[:,0]`이다.)
### 주성분에 대한 분산 비율 (Explained Variance Ratio)
또다른 매우 유용한 정보로 `explained_variance_ratio_`변수를 통해 사용이 가능한 각 주성분에 대한 `설명되는 분산도 비율(Explained Variance Ratio)`이다. 이는 각각의 주성분의 축을 따라 놓여있는 데이터 세트의 분산의 비율을 나타낸다. 예시로 그림 8-2에 나타나있는 3차원 데이터 세트의 첫번째와 두번째 주선분의 설명되는 분산도 비율을 보자.
```
>>> pca.explained_variance_ratio_
array([ 0.84248607,  0.14631839])
```

## 올바른 차원의 수 구하기
임의적으로 차원수를 구하는 것 대신에, 일반적으로 분산도가 충분히 높은 비율(95%)까지 올리는 차원의 수를 고르는 것이 적절하다. 당연히 데이터를 시각화를 위해서는 2차원이나 3차원으로 줄이는 것이 아닌이상, 2차원이나 3차원으로 데이터를 줄이는 것은 옳지 못한 방향일 수도 있다. 

다음의 코드는 차원감소법 없이 PCA를 연산하고 학습 데이터 세트의 분산도 95%를 유지를 해줄 수 있는 최소 차원수를 연산한다.
```
pca = PCA()
pca.fit(X_train)
cumsum = np.cumsum(pca.explained_variance_ratio_)
d = np.argmax(cumsum >= 0.95) + 1
```
이제 `n_components=d`라고 설정하고 다시 PCA를 돌려보자. 하지만 더 나은 옵션이 있다. 유지하고자하는 주성분을 명시하는 것대신에, `n_components`를 유지하고자 하는 분산도를 나타내주는 0.0~1.0 사이로 설정해보자. 
```
pca = PCA(n_components=0.95)
X_reduced = pca.fit_transform(X_train)
```
아직 또다른 옵션이 있는데, 아래의 그림으로 나와있듯이 차원 수의 함수로 설명된 분산도를 그려보는 것이다. 보통 곡선에서 팔꿈치(elbow)라고 부르는 부분이 있을 것인데, 이는 설명되는 분산치가 빠르게 올라가는 것을 멈추는 순간을 말한다. 데이터 세트의 고유의 차원수로써 생각할 수 있다. 이러한 경우, 약 100차원으로 차원수를 줄이는 것이 설명되는 분산도를 많이 잃지 않는다는 것을 볼 수 있다.
###### 그림 8-8. 차원 수의 함수로 설명된 분산도
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-8.png)

## PCA 압축
분명히 차원감소법을 사용하고 난 후에는, 학습 데이터 세트의 공간을 줄어들게 된다. 예로 분산도 95%를 유지하면서 MNIST 데이터 세트에 PCA를 적용해보자. 기존의 764 특징값들 대신 오직 150개의 특징 값만이 각각의 인스턴스에 남게될 것이다. 그래서 대부분의 분산도는 유지되면서 데이터 세트는 기존의 것보다 20% 사이즈가 감소했다. 이는 합리적인 압축 비율이면서 어떻게 분류 알고리즘의 속도가 엄청나게 올라가는지 보았다.

PCA 투영의 역변환을 적용함으로써 차원감소된 데이터세트를 784차원으로 압축을 푸는것 또한 가능하다. 당연히 투영법은 정보손실이 어느정도는 발생하기 때문에 원본 데이터로 되돌려주는것은 아니지만 원본 데이터와 비슷하게 만들어낼 수 있다. 기존 데이터와 복구된 데이터 사이의 평균 제곱 거리를 복구 에러치(*Reconstruction Error*)라고한다. 예시로 다음의 코드는 MNIST 데이터 세트를 154 차원으로 압축한 다음에, `inverse_transform()`함수를 사용해서 784 차원으로 압축을 해제하는 코드이다. 아래의 그림은 원본 데이터 세트(왼쪽)와 그에 상응하는 숫자를 압축하고 해제한 것에 대한 것을 보여준다. 어느정도 이미지 퀄리티에 손실이 존재하지만 숫자의 모양은 여전히 살아있다.
```
pca = PCA(n_components = 154)
X_reduced = pca.fit_transform(X_train)
X_recovered = pca.inverse_transform(X_reduced)
```
###### 그림 8-9. 95%의 분산도를 유지해주는 MNIST 압축
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-9.png)

아래의 공식은 역변환 공식을 보여준다.
###### Equation 8-3. 기존의 차원수로 돌아가기 위한 PCA 역변환 함수
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/Eq8-3.png)
## 증분 PCA (Incremental PCA)
PCA를 하도록 구현하면서 발생하는 문제는 SVD 알고리즘을 실행하기 위해서 전체 데이터 세트를 메모리에 적합하도록 요구한다는 것이다. 다행히도 증분 PCA (*Incremental PCA*, IPCA)라고 하는 알고리즘이 개발되었다. 학습 데이터 세트를 쪼개어서 mini-batch로 만들어주고 한번에 하나의 mini-batch를 IPCA 알고리즘에 사용하는 것이다. 학습 데이터가 아주 클 때 유용하며, 실시간 PCA에 적용할 수도 있을 것이다. 

아래의 코드는 NumPy의 `array_split()`함수를 사용해서 MNIST 데이터 세트를 100개의 mini-batch로 쪼개고, 이전에서 했던 것처럼 154차원으로 MNIST 데이터세트의 차원를 감소시켜주는 Scikit-Learn의 [`IncrementalPCA`클래스](http://goo.gl/FmdhUP)에 이 mini-batch들을 입력해준다. 전체 데이터 세트에 `fit()` 함수를 사용하는 것보다는 각각의 mini-batch에 대해서 partial_fit()함수를 호출해 사용해야만 한다는 점을 알아두자.
```
from sklearn.decomposition import IncrementalPCA

n_batches = 100
inc_pca = IncrementalPCA(n_components=154)
for X_batch in np.array_split(X_train, n_batches):
    print(".", end="") # not shown in the book
    inc_pca.partial_fit(X_batch)

X_reduced = inc_pca.transform(X_train)
```
대체적으로, NumPy의 `memmap`이라는 클래스를 사용할 수 있는데, 이는 메모리에 있는것 처럼 디스크에 있는 바이너리 파일들을 거대한 배열로 저장되도록 다룰 수 있게 해준다. 이 클래스는 필요할 때 메모리에 필요한 데이터만 불러온다. `IncrementalPCA`클래스가 어떤 주어진 시간에서 배열의 오직 작은 일부만을 사용하기 때문에 메모리의 사용량이 허용된 범위 내에 들어오게된다. 보통 `fit()`이라는 함수를 불러 사용함으로써 이를 가능케해준다.
```
X_mm = np.memmap(filename, dtype="float32", mode="readonly", shape=(m, n))

batch_size = m // n_batches
inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)
inc_pca.fit(X_mm)
```
## 확률화된 PCA (Randomized PCA)
Scikit-Learn은 PCA를 수행하느데 있어 또다른 옵션을 제공하는데, 확률화된 PCA(*Randomized PCA*)라고 하는 것을 제공한다. 이는 첫번째 d-주성분의 근사치를 빠르게 찾아주는 확률적 알고리즘이다. 이것의 연산 복잡도는 O(m X n^2)대신에 O(m X d^2) + O(d^3)이기 때문에, d가 n보다 작을 때 이전의 알고리즘보다 빨라진 것이다.
```
rnd_pca = PCA(n_components=154, svd_solver="randomized", random_state=42)
X_reduced = rnd_pca.fit_transform(X_train)
```
# Kernel PCA
Chapter 5에서, 우리는 Support Vector Machine이 비선형성을 가질 수 있도록 특징공간이라고 불리는 매우 높은 차원공간에 인스턴스를 내재적으로 배치하는 수학적 기법인 커널 기법을 다루어보았다. 기존의 공간(Original Space)에서 복잡한 비선형적인 의사결정선에 상응하는 고차원 특징 공간에 선형 의사결정선을 재현해보자.

차원 감소법에 대해서 복잡한 비선형 투영법을 수행하는 것을 가능하게 해주는 PCA를 적용하는데 같은 기법을 사용할 수 있을 것이다. 이를 커널 PCA ([Kernel PCA, kPCA](http://goo.gl/5lQT5Q))라고 불리는 것이다. 이는 투영법후에 군집의 수를 유지하는데 좋고, 심지어 베베꼬인 매니폴드에 가까이 놓여진 데이터 세트를 풀어주는 역할또한 해준다.

예시로 아래의 코드는 Scikit-Learn의 `KernelPCA`클래스는 kPCA에 RBF커널을 사용하여 구현한 것이다. 
```
from sklearn.decomposition import KernelPCA

rbf_pca = KernelPCA(n_components = 2, kernel="rbf", gamma=0.04)
X_reduced = rbf_pca.fit_transform(X)
```
아래의 그림은 선형 커널, RBF커널, 시그모이드(로지스틱)커널을 사용하여 2차원으로 Swiss roll 데이터 세트를 줄인 것이다.
###### 그림 8-10. 다양한 커널들로 kPCA를 사용하여 2차원으로 Swiss roll 데이터셋 차원감소
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-10.png)
## 커널과 튜닝된 하이퍼파라미터 선택하기
kPCA는 비지도 학습 알고리즘이기 때문에, 최고의 커널과 하이퍼파라미터 값을 고르는데 도움을 주는 분명한 평가지표가 없다. 하지만 차원감소법은 종종 준비 단계에서 지도학습을 미리 해놓기 때문에 이에 대한 최고의 수행도를 이끌어 줄 수 있는 커널과 하이퍼파라미터를 찾는데 그리드 탐색(Grid Search)을 사용할 수 있다. 예를들어 다음의 코드는 두 단계의 파이프라인을 가지고 있는데, 첫번째 단계에서는 kPCA를 사용해서 2차원으로 차원을 감소시키고, 그리고 나서 분류에 대한 로지스틱 회귀를 적용한다. 그리고 파이프라인 끝에서는 최고의 분류 정확도를 얻기 위해서 kPCA에 대해서 최고의 커널과 최고의 감마값을 찾아주는 `GridSearchCV`를 이용한다.
```
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

clf = Pipeline([
        ("kpca", KernelPCA(n_components=2)),
        ("log_reg", LogisticRegression())
    ])

param_grid = [{
        "kpca__gamma": np.linspace(0.03, 0.05, 10),
        "kpca__kernel": ["rbf", "sigmoid"]
    }]

grid_search = GridSearchCV(clf, param_grid, cv=3)
grid_search.fit(X, y)
```
최고의 커널과 하이퍼파라미터 값은 `best_params_valiables`라는 변수에 저장해둔다.
```
>>> print(grid_search.best_params_)
{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}
```
또다른 접근방법은 복구 에러에서 가장 적은 값을 산출하는 커널과 하이퍼파라미터 값을 선택하는 것이다. 하지만 복구는 선형 PCA에서는 쉽지가 않은데 이유는 다음과 같다. 아래의 그림에서 위의 왼쪽 그림은 Swiss roll 3차원 데이터 세트 원본, 위 오른쪽은 kPCA에 RBF커널을 사용하여 적용한 후 2차원 데이터 세트로 변환한 결과이다. 커널기법 덕분에, *특징맵* φ을 사용하여 (아래 오른쪽) 무한한 차원 특징 공간에 학습 데이터 세트를 맵핑하는 것에 수학적으로 맞먹으며, 변환된 학습 데이터 수를 투영하는 것은 선형 PCA를 사용하여 2차원으로 내릴수 있다. 줄여진 공간에서 주어진 인스턴스에 대해 선형 PCA단계를 뒤집는다면 복구된 점은 오리지널 공간이 아닌 특징값 공간에 놓이게된다. 특징 공간은 무한한 차원이기에 복구된 지점을 연산할 수 없기에 그러므로 복구 에러를 연산할 수 없게된다. 다행히도 복구된 지점에 가까이 배치된 오리지널 공간에 지점을 찾는것은 가능하다. 이를 원상복구(*pre-image*)라고 한다. 원상을 가지게되면, 기존의 원본 이미지와의 제곱거리를 측정할 수 있게된다. 이러면 이제 원상복구에러를 최소화해주는 커널 및 하이퍼파라미터를 선택하기만 하면 된다.
###### 그림 8-11. 커널 PCA와 원상복구 에러
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-11.png)

그렇다면 복구는 어떻게 수행되는지 궁금해할수도 있다. 하나의 솔루션은 투영된 인스턴스를 학습 데이터로 사용하고, 원본 데이터를 레이블 데이터로 사용하여 회귀모델을 지도학습하는 것이다. 아래와 같이 보여지는 코드처럼 Scikit-Learn에서 `fit_inverse_transform=True`로 설정하두었다면 자동으로 수행해줄 것이다.
```
rbf_pca = KernelPCA(n_components = 2, kernel="rbf", gamma=0.0433,
                    fit_inverse_transform=True)
X_reduced = rbf_pca.fit_transform(X)
X_preimage = rbf_pca.inverse_transform(X_reduced)
```
```
기본값으로 "fit_inverse_transform=False"로 설정되어있으면 "KernelPCA"는 "inverse_transfrom()"
함수가 없다. 이 함수는 오직 "fit_inverse_transform=True"여야만 사용할 수 있게되는 함수이다.
```
이제 원상복구에러 또한 연산할 수 있다.
```
>>> from sklearn.metrics import mean_squared_error
>>> mean_squared_error(X, X_preimage)
32.786308795766139
```
이제 이 원상복구에러를 최소화해주는 커널과 하이퍼파라미터를 찾아내는데 cross-validation을 통해 grid-search를 할 수 있다.

## LLE
근접선형위상배치법([*Locally Linear Embedding*](https://goo.gl/iA9bns), LLE)은 또다른 아주 강력한 비선형 차원 감소법이다. 이전의 알고리즘처럼 투영법에 의존적이지 않은 매니포들 학습 기술이다. LLE는 각각의 인스턴스들이 가장 가까운 이웃들에게 서로 얼마나 선형적으로 관계가 있는지에 대해서 측정하고나서 근접 관계가 최고로 잘 보존된 학습 데이터 세트의 하위 차원 표상을 찾게된다. 이는 특히 꼬여있는 매니폴드를 펴놓는데 좋으며 더 특별한 것은 노이즈가 많이 발생하지 않는다는 점이다. 

예시로 아래의 코드는 swiss roll을 풀어내기 위한 Scikit-Learn의 `LocallyLinearEmbedding`이라는 클래스를 사용한다. 결과로 나오는 이차원 데이터 세트는 아래의 그림에 나와있다. 보다시피, Swiss roll이 완벽하게 펼쳐졌으며, 인스턴스 사이의 거리들이 근접하게 잘 보존되었다. 하지만 이런 거리들은 더 거대한 스케일에 대해서는 잘 보존되지는 못하는데, 아래 그림의 Swiss roll을 펼친 왼쪽 부분을 보면 여전히 데이터가 밀집되어 있는 반면에 오른쪽 부분은 갈라졌다. 그럼에도 불구하고 LLE는 매니폴드 모델링을 아주 잘한다.
```
from sklearn.manifold import LocallyLinearEmbedding

lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)
X_reduced = lle.fit_transform(X)
```
###### 그림 8-12. LLE를 사용하여 Swiss roll 풀어내기
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-12.png)

여기에 LLE가 작동하는 방식이 있다. 먼저 각각의 학습 인스턴스 x^(i)에 대해서 알고리즘은 k개의 가장 가까운 이웃들을 찾아낸다.(실행된 코드에서는 k가 10임) 그리고나서, 이러한 이웃점들의 선형 함수로써 x^(i) 복구를 시도한다. 좀 더 명시적으로, x^(i)들 사이 거리에 제곱한 값같은 가중치 wij를 찾고, x^(j)가 x^(i)의 k 개의 가장 가까운 이웃이 아니라면 wij=0으로 가정하여서 ![](https://render.githubusercontent.com/render/math?math=%5Csum_%7Bj%3D1%7D%5E%7Bm%7D%7Bw_%7Bi%2Cj%7D%5Cmathbf%7Bx%7D%5E%7B%28j%29%7D%7D&mode=inline)를 가능한 작도록 한다. LLE의 첫번째 단계는 아래의 공식으로 보여지고 있으며, constrained optimization 문제이다. **W**는 모든 가중치들 wij를 포함하고 있는 가중치 행렬이다. 두번째 제한사항은 각각의 학습 인스턴스 x^(i)에 대해서 가중치들을 일반화하는 것이다.
###### Equation 8-4. LLE 1단계 : 선형 모델링 근접 관계들
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/Eq8-4.png)

이 단계후에는, (가중치 ŵij를 포함한) 가중치 행렬 Ŵ는 학습 인스턴스 사이의 근접 선형 관계를 복호화한다. 이제 두번째 단계는 가능한 이러한 근접 관계들을 최대한 많이 유지하면서도 (d<n)d-차원 공간에 학습인스턴스를 맵핑하는 것이다. ![](https://render.githubusercontent.com/render/math?math=%5Cmathbf%7Bz%7D%5E%7B%28i%29%7D&mode=inline)가 d-차원 공간에 X^(i)의 이미지를 말한다면, 우리는 거리차이를 가능한 작게만드는![](https://render.githubusercontent.com/render/math?math=%5Cmathbf%7Bz%7D%5E%7B%28i%29%7D&mode=inline)와 ![](https://render.githubusercontent.com/render/math?math=%5Csum_%7Bj%3D1%7D%5E%7Bm%7D%7B%5Chat%7Bw%7D_%7Bi%2Cj%7D%5Cmathbf%7Bz%7D%5E%7B%28j%29%7D%7D&mode=inline)사이의 거리차이를 제곱하고 싶을 것이다. 이것은 아래의 식에도 나와있으며, unconstrained optimization 문제에서 아이디어를 주도한다. 첫번째 단계와 크게 다를것이 없어 보일지라도, 인스턴스가 고정되는 것을 유지하는 대신에 최적점을 찾는 것으로, 우리는 역으로 하위차원공간에서 인스턴스의 이미지의 최적점을 찾으면서 가중치가 변하지 못하도록 해주는 것이다. **Z**는 모든 Z^(i)가 포함된 행렬이다.


###### Equation 8-5. LLE 2단계 : 관계도를 유지하면서 차원수 줄이기
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/Eq8-5.png)

Scikit-Learn의 LLE 구현은 다음과 같은 연산 복잡도를 가진다. K개의 가장 가까운 이웃을 찾는데에 `O(mlog(m)nlog(k))`, 가중치를 업데이트하는데에 `O(mnk^3)`, 하위차원 표상을 복구하는데에는 `O(dm^2)`의 복잡도를 가지게된다. 불행하게도, 마지막 식에서 m^2는 매우 큰 데이터 세트에 대해서는 스케일링이 잘 수행되지 못한다. 

# 또다른 차원축소법 기술
차원감소법 기술은 아직도 많은 것들이 존재하는데, Scikit-Learn에서 사용할 수 있는 것들도 있다. 다음이 가장 인기가 있는 것들 중 하나이다.
* 다중차원스케일링(*Multidimensional Scaling*, MDS)은 인스턴스 사이의 거리를 유지하도록 하면서 차원수를 줄인다.
* *Isomap* 은 각각의 인스턴스가 그 주위의 가장 가까운 이웃 인스턴스가 연결된 그래프를 그려주는 것이다. 인스턴스 사이의 측지선(*geodesic*) 거리를 유지하면서도 차원수를 줄여준다.
* T개의 분산 기반 확률적 근접 위상 배치법(*t-Distributed Stochastic Meighbor Embedding*)은 비슷한 인스턴스 끼리는 가까이 해주고 비슷하지 않은 인스턴스끼리는 거리를 멀게 해주면서 차원수도 줄여준다. 대개 시각화를 하는데 자주 사용하고는 하는데, 특시 고차원 공간에 있는 인스턴스 군집을 시각화하는데 사용한다.
* 선형판별분석법(*Linear Discriminant Analysis*)은 실제로는 분류 알고리즘이지만, 학습을 하는 동안에 클래스들 사이에 판별축을 학습하고 이러한 축들이 데이터를 투영시키는 하이퍼플레인을 정의를 해주는데 사용되고는 한다. 투영법이 가능한 서로 클래스 끼리 멀게 유지되도록 해주는 이점이 있어, LDA는 SVM분류 모델같이 또다른 분류모델을 실행하기전에 차원을 감소시켜주는 좋은 기법이다. 

###### 그림 8-13. 다양한 기술들을 사용해서 Swiss roll을 2차원으로 줄이기
![](https://github.com/Hahnnz/Hands_on_ML-Kor/blob/master/Book_images/08/8-13.png)


**[뒤로 돌아가기](https://github.com/Hahnnz/handson_ml-Kor/)**
